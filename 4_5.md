Halo,从6开始提供的代码是用的较简单版本的莉沫酱包含半身），但对于我所在的项目来说复杂度太高。  
所以在这里我也提供了对**过于简单版本的莉沫酱(仅捕捉头部)**部分的代码。

对于原来部分的代码风格暂时没有改变，而且这么写有一种背德感=-=，紧张刺激。  
但我改变了相对路径的引用方式，举例：
原本的`../res/std_face.jpg`改成了`./res/std_face.jpg`。
原本的`深度.yaml`改成了`./4.5/深度.yaml`。

这么改让我能够直接在项目根目录下面运行它们，而不用切换工作目录到子文件夹。也是vscode不太方便。
相对于4你需要增加环境mediapipe。

```cmd
pip install mediapipe==0.10.11
```

**4.5中相对4的改变：**
* 虚境只是封装成类，可以参考[一时休战](5.md)。
* 现实的人脸特征点检测用google的mediapipe替代dlib。
* 增加mediapipe体验.py，你可以在这里体验并且自定义构造点。

dlib捕捉起来断断续续的，特别是超过半侧脸关键点消失。因为查了一下dlib用的是机器学习方法，泛化性差在我这张脸上体现的淋漓尽致。
相对而言mediapipe速度相当快。画面比较丝滑。另外全脸的face_mesh也让我想到制作脸部变形的可能。小幅度的。

![](https://storage.googleapis.com/mediapipe-assets/documentation/mediapipe_face_landmark_fullsize.png)

[这个是面部index索引图原图网址，如果你看不清或者没有加载出来可以到这里。](https://storage.googleapis.com/mediapipe-assets/documentation/mediapipe_face_landmark_fullsize.png)

